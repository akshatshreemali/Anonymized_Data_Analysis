{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing all the necessary packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob # to be used to import multiple files at once\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.3.1-bin-hadoop2.7')\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('spark').getOrCreate()\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.classification import LogisticRegression,LogisticRegressionModel,LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder,TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if all inout files are covered or not\n",
    "path ='/home/ubuntu/Notebooks'\n",
    "filenames = glob.glob( path+\"/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ubuntu/Notebooks/part-00007-tid-6056519413201330783-119422a4-5c84-4461-ba64-4a5e2a1d4acd-36-c000.snappy.parquet', '/home/ubuntu/Notebooks/part-00006-tid-6056519413201330783-119422a4-5c84-4461-ba64-4a5e2a1d4acd-35-c000.snappy.parquet', '/home/ubuntu/Notebooks/part-00000-tid-6056519413201330783-119422a4-5c84-4461-ba64-4a5e2a1d4acd-29-c000.snappy.parquet', '/home/ubuntu/Notebooks/part-00003-tid-6056519413201330783-119422a4-5c84-4461-ba64-4a5e2a1d4acd-32-c000.snappy.parquet', '/home/ubuntu/Notebooks/part-00004-tid-6056519413201330783-119422a4-5c84-4461-ba64-4a5e2a1d4acd-33-c000.snappy.parquet', '/home/ubuntu/Notebooks/part-00001-tid-6056519413201330783-119422a4-5c84-4461-ba64-4a5e2a1d4acd-30-c000.snappy.parquet', '/home/ubuntu/Notebooks/part-00002-tid-6056519413201330783-119422a4-5c84-4461-ba64-4a5e2a1d4acd-31-c000.snappy.parquet']\n"
     ]
    }
   ],
   "source": [
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating spark dataframe by reading all the input files\n",
    "lucid_dataset=spark.read.format(\"parquet\").option(\"header\", \"true\").load(\"/home/ubuntu/Notebooks/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6883958"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of rows in dataset?\n",
    "lucid_dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of columns? in dataset?\n",
    "len(lucid_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|    1|\n",
      "|    0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lucid_dataset.select('label').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|    1|    368|\n",
      "|    0|6883590|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lucid_dataset.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is an highly imbalanced dataset with 99.995 % are 0's(negative class) and 0.005 % are 1's (positive class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Steps:\n",
    "<b> Though the data is cleaned, but below are the steps which I would have followed to clean the data and identify issues </b>\n",
    "\n",
    "1. Check for nulls in the data. Would have written a pyspark script which will give us, what columns contain null values and how much proportion of nulls they have\n",
    "2. Depending on the proportion, would have either deleted the column or replaced null with the mean value (in case of continuous and discrete value) or replaced with 0 in case of binary\n",
    "3. Identifying and replacing the null value should proceed with caution since it will be dependent on the type of column\n",
    "4. The next step would be to identify if we have any duplicates in our data, again a pyspark script I have written which helps in identifying duplicate rows as well as removes it\n",
    "5. In case of categorical/text data, converting the data into numeric, so that it can be used for analysis (using one hot encoder)\n",
    "6. Renaming of columns, each column should have a meaningful names so that it becomes easy to understrand\n",
    "7. Standardizing data --> eg: if there are two columns merged into one then we have to separate such columns\n",
    "8. Converting datatypes into their respective format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Steps to identify important variables and create model :\n",
    "\n",
    "a. <b> Separate the data into training and test. All the analysis,feature selection would be on training data only </b>\n",
    "\n",
    "b. <b> Separate the categorical(binary) variables and continuous/discrete variables </b>\n",
    "\n",
    "\n",
    "c. <b> Using Chi-Square selector, identify important features from the categorical variables </b>\n",
    "\n",
    "d. <b> Build Logistic Regression model using the important features and identify variables which are important or have zero impact on the model </b>\n",
    "\n",
    "e. <b> Build logistic regression/SVM model on the continuous/discrete variables and identify variables which are impactful and which are not </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "train_data,test_data=lucid_dataset.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def column_binary(dataframe):\n",
    "    \"\"\"\n",
    "    This function will separate the categorical(binary) variables with continuous/discrete and will give a list of columns which have o  and 1\n",
    "    \"\"\"\n",
    "    cols=[]\n",
    "    for i in dataframe.columns[1:]:\n",
    "        if dataframe.select(i).distinct().count()==2:\n",
    "            cols.append(i)\n",
    "    cols.append('label') # appending label column to capture output in new dataframe\n",
    "    return cols \n",
    "cols=column_binary(lucid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_features(data):\n",
    "    \"\"\"\n",
    "    # This function creates a dataframe containing only categorical data and uses Vector assembler to create the features and\n",
    "      dataframe required to perform Chi square test\n",
    "    \"\"\"\n",
    "    category_data=data.select(cols)\n",
    "    assembler=VectorAssembler(inputCols=cols[1:],outputCol='features')\n",
    "    category_data=assembler.transform(category_data)\n",
    "    return category_data\n",
    "category_data=create_features(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Chisq(data):\n",
    "    \"\"\"\n",
    "    # ChiSqSelector stands for Chi-Squared feature selection. It operates on labeled data with categorical features. \n",
    "    # ChiSqSelector uses the Chi-Squared test of independence to decide which features to choose\n",
    "    # It takes category_data as the input since the input should contain only categorical data\n",
    "    \"\"\"\n",
    "    selector = ChiSqSelector(numTopFeatures=50, featuresCol=\"features\",outputCol=\"selectedFeatures\", labelCol=\"label\")\n",
    "    model = selector.fit(data)\n",
    "    feature=model.transform(data).head().selectedFeatures\n",
    "    column_list=(model.selectedFeatures)\n",
    "    return column_list\n",
    "\n",
    "column_list=Chisq(category_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def useful_columns(data):\n",
    "    \"\"\"\n",
    "    # This function takes category_data as the input and creates a list containing all the selected variables from chisquare test\n",
    "    # It uses the column_list variable from Chisq function's output to build the list\n",
    "    \"\"\"\n",
    "    q=data.columns\n",
    "    output=['label']\n",
    "    for i in column_list:\n",
    "        output.append(q[i])\n",
    "    return output    \n",
    "\n",
    "output=useful_columns(category_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=LogisticRegression() # Initializing Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_function_features(data):\n",
    "    \"\"\"\n",
    "    # This function takes train_data as the input and creates a dataframe containing all binary/categorical variables\n",
    "    # It then transforms them into features, to be required for Logistic Regression\n",
    "    # Finally it calculates all the coefficients and captures them into a dataframe containing all the columns and coefficients\n",
    "    \"\"\"\n",
    "    cat_train_data=data.select(output)\n",
    "    assembler=VectorAssembler(inputCols=cat_train_data.columns[1:],outputCol='features')\n",
    "    cat_train_data=assembler.transform(cat_train_data)\n",
    "    lr_model=lr.fit(cat_train_data)\n",
    "    lr_model.save('category_model')\n",
    "    data_array = []\n",
    "    column_schema=sch=cat_train_data.columns[1:]\n",
    "    for i in range (0,len(lr_model.coefficients)) :\n",
    "         data_array.extend([(column_schema[i], float(lr_model.coefficients[i]))])\n",
    "    df = spark.createDataFrame(data = data_array, schema = [\"columns\", \"coefficients\"])\n",
    "    return df\n",
    "\n",
    "df=cat_function_features(category_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_model=LogisticRegressionModel.load('category_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In logistic Regression : \n",
    "\n",
    "-> A negative coefficient simply implies that the probability that the event identified by the dependent variable happens decreases as the value of the independent variable increases\n",
    "\n",
    "-> A positive coefficient simply implies that the probability that the event identified by the dependent variable happens increases as the value of the independent variable increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_zero=df.filter('coefficients!=0')\n",
    "positive_variable=df_no_zero.filter('coefficients>0.05')\n",
    "negative_variable=df_no_zero.filter('coefficients<-0.05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f445 f458 f301 f309 f265 f253 f325 f183 f451 f275 f162 f466 f259 f421 f298 f179 f153 f193 f502 f326 f305 f150 f202 f365 f223 f340 f172 f494 f306 f449 f268 f394 f395 f300 f333 f324 f187 f350 "
     ]
    }
   ],
   "source": [
    "# Features which  impact the output variable by going in negative direction are (ordered from their impact/ variation):\n",
    "var1=negative_variable.orderBy(negative_variable['coefficients'].asc()).select('columns').rdd.flatMap(lambda x: x).collect()\n",
    "for x in var1:\n",
    "    print(x, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f478 f228 f173 f470 f208 f113 f163 f145 f180 f430 f154 "
     ]
    }
   ],
   "source": [
    "var2=positive_variable.orderBy(positive_variable['coefficients'].asc()).select('columns').rdd.flatMap(lambda x: x).collect()\n",
    "for x in var2:\n",
    "    print(x, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numeric_data(data):\n",
    "    \"\"\"\n",
    "    # This function takes train_data as the input and creates a dataframe containing all continuous/discrete variables\n",
    "    # It then transforms them into features, to be required for Logistic Regression\n",
    "    # Finally it calculates all the coefficients and captures them into a dataframe containing all the columns and coefficients\n",
    "    \"\"\"\n",
    "    numeric_data=data.select([c for c in data.columns if c not in cols[0:-1]])\n",
    "    assembler=VectorAssembler(inputCols=numeric_data.columns[1:],outputCol='features')\n",
    "    numeric_data=assembler.transform(numeric_data)\n",
    "    n_model=lr.fit(numeric_data)\n",
    "    n_model.save('numeric_model')\n",
    "    data_array = []\n",
    "    for i in range (0,len(n_model.coefficients)) :\n",
    "        data_array.extend([(numeric_columns[i], float(n_model.coefficients[i]))])\n",
    "    df = spark.createDataFrame(data = data_array, schema = [\"columns\", \"coefficients\"])\n",
    "    return df\n",
    "\n",
    "df=numeric_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_model=LogisticRegressionModel.load('numeric_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Steps to identify/ important variables:\n",
    "\n",
    "#### a. We will now try to drop those variables whose coefficients values are low and zero.\n",
    "#### b. Since logistic regression is log probability, bigger the number, better are the odds to increase the probability of the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdf=df.filter('coefficients!=0.0')\n",
    "negativedf=newdf.filter('coefficients<-1')\n",
    "positivedf=newdf.filter('coefficients>1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(negativedf.count()) # total number of variables which impact the output while they are decreasing\n",
    "print(positivedf.count()) # total number of variables which impact the output while they are increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f12 f68 f18 f65 f88 f403 f73 f63 f67 f35 f158 f313 f499 f69 f199 f425 f127 f66 f465 f17 f147 f75 f101 f501 f471 f293 f89 "
     ]
    }
   ],
   "source": [
    "# Features which  impact the output variable by going in negative direction are (ordered from their impact/ variation):\n",
    "var3=negativedf.orderBy(negativedf['coefficients'].asc()).select('columns').rdd.flatMap(lambda x: x).collect()\n",
    "for x in var3:\n",
    "    print(x, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f366 f6 f489 f115 f122 f330 f272 f369 f488 f491 f483 f258 "
     ]
    }
   ],
   "source": [
    "# Features which are impact the output variable by going in negative direction are:\n",
    "var4=positivedf.orderBy(positivedf['coefficients'].desc()).select('columns').rdd.flatMap(lambda x: x).collect()\n",
    "for x in var4:\n",
    "    print(x, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Procedure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Out of the 501 features, an important task was to identify the important features, below are the steps I took: </b>\n",
    "\n",
    "1. The dataset has both binary and continuous variables. Separate these columns into a different dataframe\n",
    "2. The result was, there were 335 binary columns and 166 continuous variables\n",
    "3. Using Chi square selector on the binary column dataframe, identified the top 50 features in that dataframe and stored them\n",
    "4. Created a logistic regression model on those column and got rid of those variables whose coefficients were zero\n",
    "5. Majority of the features had a negative coefficients and it means that, they impact the output variable positively when they decrease or in our case , they are zero (masked as zero in case of categorical)\n",
    "6. For continuous/discrete variables, I created a logistic regression model and got their coefficients\n",
    "7. Out of 166 columns, 24 had zero coefficients and thus were ruled out from analysis\n",
    "8. Many variables had very low coefficients(in negative exponential terms) and thus I decided to rule them out \n",
    "9. Finally out of 166, I identified 39 columns which were impactful for the output probability \n",
    "10. 27 were those which impacted the output probability inversely. Their decrease was increasing the probability\n",
    "11. Since it's PySpark, I could not use Anova or RFE which would have further helped in identifying important features or would have gotten rid of more variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Features are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "1. Features/variables <b>\"f445, f458, f301, f309, f265, f253, f325, f183, f451, f275 </b> are the top variables which impact/increase the output probability ( of 1 ) when they are 0\n",
    "\n",
    "2. The other cateogorical/binary variables which increase the probability of the output to be 1 when they are themselves 1 are : <b> \"f478 ,f228, f173, f470, f208, f113, f163\" </b>\n",
    "\n",
    "3. <b>\"f12, f68, f18, f65, f88, f403, f73, f63, f67, f35, f158, f313\"</b> are the top 12 continuous/discrete variables by which probability that the event identified by the dependent variable happens decreases as the value of the independent variable increases\n",
    "\n",
    "4. <b>\"f366, f6, f489, f115, f122, f330, f272, f369, f488, f491, f483, f258\" </b>are top 12 continuous/discrete variables which impact output probability positively when they increase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handling the class imbalance by creating weights for our 0's and 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of features used are:  88\n"
     ]
    }
   ],
   "source": [
    "# Creating a list of final variables to be used \n",
    "final_variables=var1+var2+var3+var4\n",
    "final_variables.append('label')\n",
    "print('total number of features used are: ',len(final_variables)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Slicing training and test data with the final features and variables\n",
    "train_data=train_data.select(final_variables)\n",
    "test_data=test_data.select(final_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def balanceDataset(data): \n",
    "    \"\"\"\n",
    "    This function is used to created weights column.\n",
    "    It takes a dataset as an input and it should have 'label' column in it\n",
    "    Creates a separate dataframe with assigned weights required to handle Class Imbalance\n",
    "    \n",
    "    \"\"\"\n",
    "    #// Re-balancing (weighting) of records to be used in the logistic loss objective function\n",
    "    numNegatives = data.filter(\"label == 0\").count() #5505244\n",
    "    datasetSize =  data.count() # 5505526\n",
    "    balancingRatio = (datasetSize - numNegatives) / datasetSize\n",
    "    calculateWeights =udf(lambda d: (1 *  balancingRatio) if d==0.0 else (1 * (1.0 - balancingRatio)), DoubleType())\n",
    "    weightedDataset = data.withColumn(\"classWeightCol\", calculateWeights(data.label))\n",
    "    return weightedDataset\n",
    "\n",
    "weightedDataset=balanceDataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating our test and train features\n",
    "assembler=VectorAssembler(inputCols=weightedDataset.columns[1:-1],outputCol='features')\n",
    "train_data=assembler.transform(weightedDataset)\n",
    "test_data=assembler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initializing our Logistic Regression model and getting the F1 score and AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of model logistic was: 0.8663449465447742\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr=LogisticRegression(weightCol='classWeightCol') # weights col will take into account the class imbalance\n",
    "final_model=model.fit(train_data)\n",
    "prediction=final_model.transform(test_data)\n",
    "f1_eval = MulticlassClassificationEvaluator(metricName='f1')\n",
    "lr_f1= f1_eval.evaluate(prediction)\n",
    "final_lr.save('Logistic_regression_model')\n",
    "\n",
    "print(\"F1 score of model logistic was: {}\".format(lr_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC is 0.882231605978899\n"
     ]
    }
   ],
   "source": [
    "auc_eval = BinaryClassificationEvaluator()\n",
    "print('AUC is', auc_eval.evaluate(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1053570  324935]\n",
      " [     11      64]]\n"
     ]
    }
   ],
   "source": [
    "# Creating a confusion matrix\n",
    "c=prediction.select('label').toPandas()\n",
    "d=prediction.select('prediction').toPandas()\n",
    "c=np.array(c)\n",
    "d=np.array(d)\n",
    "print(confusion_matrix(c,d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our model is predicting 64 correct 1's but has some False negatives. \n",
    "#### False Positives are quite low only (11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Implementing LinearSVM \n",
    "\n",
    "# svm=LinearSVC(weightCol='classWeightCol')\n",
    "# mo=svm.fit(train_data)\n",
    "# svm_pred=mo.transform(test_data)\n",
    "# svm_f1 = acc_eval.evaluate(svm_pred)\n",
    "# print(\"F1 score of model svm was: {}\".format(svm_f1))\n",
    "# sv_c=svm_pred.select('label').toPandas()\n",
    "# sv_d=svm_pred.select('prediction').toPandas()\n",
    "# sv_c=np.array(sv_c)\n",
    "# sv_d=np.array(sv_d)\n",
    "# print(confusion_matrix(sv_c,sv_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "# # specify layers for the neural network:\n",
    "# # input layer of size 4 (features), two intermediate of size 5 and 4\n",
    "# # and output of size 3 (classes)\n",
    "# layers = [88, 88, 100, 2]\n",
    "\n",
    "# # create the trainer and set its parameters\n",
    "# trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "# # train the model\n",
    "# model = trainer.fit(train_data)\n",
    "\n",
    "# # compute accuracy on the test set\n",
    "# result = model.transform(test_data)\n",
    "# nn_eval = MulticlassClassificationEvaluator(metricName='f1')\n",
    "# nn_f1= nn_eval.evaluate(result)\n",
    "# model.save('neural_model')\n",
    "\n",
    "# print(\"F1 score of model NN was: {}\".format(nn_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Model for better scores and identifying best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [ 0.5, 2.0, 1.5])\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "             .addGrid(lr.maxIter, [ 50, 100, 200])\n",
    "             .build())\n",
    "\n",
    "tvs = TrainValidationSplit(estimator=lr,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=MulticlassClassificationEvaluator(),\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)  \n",
    "model=tvs.fit(train_data)\n",
    "predictions = model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for best model is  0.8405825143836786\n"
     ]
    }
   ],
   "source": [
    "best_model=model.bestModel\n",
    "best_pred=best_model.transform(test_data)\n",
    "best_eval=MulticlassClassificationEvaluator()\n",
    "f1=best_eval.evaluate(best_pred)\n",
    "print('f1 score for best model is ',f1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_47a78f2e0a1e803395bc', name='regParam', doc='regularization parameter (>= 0).'): 0.5,\n",
       " Param(parent='LogisticRegression_47a78f2e0a1e803395bc', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0,\n",
       " Param(parent='LogisticRegression_47a78f2e0a1e803395bc', name='maxIter', doc='max number of iterations (>= 0).'): 50}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets parameters of your best model in terms of train validation split\n",
    "import numpy as np\n",
    "\n",
    "# gets parameters of your best model in terms of train validation split\n",
    "model.getEstimatorParamMaps()[np.argmax(model.validationMetrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Analysis\n",
    "<b> 1. The F1 score of the model is 0.86 and the AUC is 0.88 </b>\n",
    "\n",
    "<b> 2. F1 Score is the weighted average of Precision and Recall. In case of uneven class distribution like in our dataset, F1 score helps in evaluating the model </b>\n",
    "\n",
    "<b> 3. After tuning the parameters using train-validation split, the overall model F1 score came out to be 0.84. Thus we can say that the initial model parameters are the best and the score is valid </b>\n",
    "\n",
    "<b> 4. The confusion matrix results shows that, our model predicted total 64 correct positives ( keeping in mind that this percentage is very high). It has fewer False Positives but sufficiently high False Negatives </b>\n",
    "\n",
    "<b> 5. F1-score could have been better if Linear SVM was used, but it ran continuously and eventually had to kill it. But I have written the code which will evaluate the performance </b>\n",
    "    \n",
    "<b> 6. Multilayer Perceptron Classifier also like SVM ran for couple of hours and had to kill it eventually. Again, I have attached the code used </b>\n",
    "\n",
    "<b> 7. If my AWS server was more powerful, I would have used Python instead of Pandas and would have leveraged even more powerful algorithms with better feature selection like Anova,RFE and models like XGBoost and even ANN (Keras) </b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms used: Logistic Regression\n",
    "## Algorithms to be used if I had more time and bigger server: LinearSVM, MultiLayer Perceptron Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
